import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
import numpy as np
import matplotlib.pyplot as plt
import os

# --- 1. Set Up File Paths (from your notebook) ---
# These paths must be correct on your computer
train_dataset_path = r'C:\Users\niles\Downloads\brain tumour\Training'
test_dataset_path = r'C:\Users\niles\Downloads\brain tumour\Testing'

# --- 2. Create Image Generators ---
INPUT_SHAPE = (224, 224, 3)
BATCH_SIZE = 32

# Note: Using only rescale for a minimal example
# Your original augmentation is good for improving accuracy
train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dataset_path,
    target_size=(INPUT_SHAPE[0], INPUT_SHAPE[1]),
    batch_size=BATCH_SIZE,
    class_mode='categorical' # For 4 classes
)

test_generator = test_datagen.flow_from_directory(
    test_dataset_path,
    target_size=(INPUT_SHAPE[0], INPUT_SHAPE[1]),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

# Get class names from the generator
class_names = list(train_generator.class_indices.keys())
print(f"Found classes: {class_names}")

# --- 3. Define the CNN Model (from your notebook) ---
model = Sequential([
    Conv2D(64, kernel_size=3, input_shape=INPUT_SHAPE, activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(32, kernel_size=3, activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(16, kernel_size=3, activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(256, activation='relu'),
    Dense(384, activation='relu'),
    Dense(256, activation='relu'),
    Dense(4, activation='softmax') # 4 classes, so softmax
])

# 4. Compile the Model
model.compile(
    optimizer='adam', 
    loss='categorical_crossentropy', 
    metrics=['accuracy']
)

# 5. Train the Model (Corrected steps)
print("\n--- Training the model ---")
history = model.fit(
    train_generator,
    epochs=5, # Using 5 for a minimal run
    validation_data=test_generator,
    steps_per_epoch=train_generator.samples // BATCH_SIZE, # Corrected
    validation_steps=test_generator.samples // BATCH_SIZE  # Corrected
)

# 6. Plot Training & Validation Graphs
print("\n--- Plotting training history ---")
plt.figure(figsize=(12, 4))

# Plot Accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.savefig('brain_tumor_accuracy.png')

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.savefig('brain_tumor_loss.png')

plt.show()
print("Saved training graphs to 'brain_tumor_accuracy.png' and 'brain_tumor_loss.png'")

# 7. Test and Display 5 Sample Predictions
print("\n--- Displaying individual predictions ---")

# Get one batch of test images and labels
x_test_batch, y_test_batch = next(test_generator)

# Make predictions on the first 5 images
predictions = model.predict(x_test_batch[:5])
predicted_indices = np.argmax(predictions, axis=1)
actual_indices = np.argmax(y_test_batch[:5], axis=1)

# Set up a 1x5 grid
plt.figure(figsize=(15, 4))
for i in range(5):
    plt.subplot(1, 5, i + 1)
    
    # Display the image
    plt.imshow(x_test_batch[i])
    
    # Get the string name for the labels
    pred_name = class_names[predicted_indices[i]]
    actual_name = class_names[actual_indices[i]]
    
    plt.title(f"Pred: {pred_name}\nActual: {actual_name}")
    plt.axis('off')

plt.tight_layout()
plt.savefig('brain_tumor_predictions.png')
print("Saved 5 sample predictions to 'brain_tumor_predictions.png'")
plt.show()
